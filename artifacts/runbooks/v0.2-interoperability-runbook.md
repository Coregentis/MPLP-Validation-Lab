# MPLP v0.2 Implementation Runbook

> **Status**: Ready for Execution  
> **Global Locks**: BYO execution, local-cli evaluator, truth-source-first

---

## Global Constraints

| Constraint | Enforcement |
|------------|-------------|
| BYO execution | All READMEs must retain fixed boundary block |
| Evaluator | Local CLI only (no hosted API) |
| Schema fields | Use existing schema only; no new field types |
| Determinism | Fixed timestamps, seeded UUIDs, sorted JSON |

---

## Phase I — W6 Pack Generators

### W6-1: LangChain Pack Generator

**Files**
- `tests/cross-substrate/gf-01/langchain/generate_pack.py`
- `tests/cross-substrate/gf-01/langchain/requirements.txt`
- `tests/cross-substrate/gf-01/langchain/README.md` ✅ (done)

**Determinism**
```python
# Fixed timestamp
ISO_TIMESTAMP = "2026-01-01T00:00:00Z"

# Seeded UUID
import uuid
NAMESPACE = uuid.UUID("...")
step_id = uuid.uuid5(NAMESPACE, f"step-{i}")

# FakeListLLM
from langchain_community.llms.fake import FakeListLLM
llm = FakeListLLM(responses=["Step 1...", "Step 2...", "Step 3..."])

# Sorted JSON
json.dumps(data, sort_keys=True, indent=2)
```

**DoD**
```bash
cd tests/cross-substrate/gf-01/langchain
python generate_pack.py

# Verify minimums
ls pack/artifacts/{context.json,plan.json,trace.json}
ls pack/timeline/events.ndjson
ls pack/integrity/
```

---

### W6-2: A2A Pack Generator

**Files**
- `tests/cross-substrate/gf-01/a2a/generate_pack.sh`

**DoD**
```bash
cd tests/cross-substrate/gf-01/a2a
bash generate_pack.sh

# Verify same scenario
diff <(jq .scenario_id ../langchain/pack/artifacts/context.json) \
     <(jq .scenario_id pack/artifacts/context.json)
```

---

## Phase II — Local Evaluator Integration

### W6-3: Local Evaluator CLI

**Entry Point**
```bash
# Add to W6 README
pnpm evaluator -- --ruleset ruleset-1.0 --pack <path>
```

**DoD**
```bash
# LangChain pack
pnpm evaluator -- --ruleset ruleset-1.0 \
  --pack tests/cross-substrate/gf-01/langchain/pack

# A2A pack
pnpm evaluator -- --ruleset ruleset-1.0 \
  --pack tests/cross-substrate/gf-01/a2a/pack

# Verify hash stability
# Run twice, hashes must match
```

---

### W6-4: verify_equivalence.ts

**Files**
- `tests/cross-substrate/gf-01/verify_equivalence.ts`
- `Validation_Lab/releases/v0.2/artifacts/equivalence/gf-01.json` (output)

**Implementation**
```typescript
async function verify() {
  // Stage 1: Evidence minimums
  const min1 = checkMinimums(langchainPack);
  const min2 = checkMinimums(a2aPack);
  
  // Stage 2: Call local evaluator
  const v1 = await runEvaluator(langchainPack);
  const v2 = await runEvaluator(a2aPack);
  
  // Output record (no PASS/FAIL text)
  return {
    scenario_id: "gf-01",
    evaluator: "local-cli",
    evaluator_version: getGitSha(),
    verdict_match: v1.hash === v2.hash,
    evidence_minimums: { /* all true */ }
  };
}
```

**DoD**
```bash
npx tsx verify_equivalence.ts --evaluator=local-cli

# Output must exist
cat Validation_Lab/releases/v0.2/artifacts/equivalence/gf-01.json

# Verify schema
npx ajv validate \
  -s governance/schemas/equivalence-record.schema.json \
  -d Validation_Lab/releases/v0.2/artifacts/equivalence/gf-01.json
```

---

## Phase III — Curated Allowlist

### W6-5: Add Reproduced Runs

**File**
- `Validation_Lab/data/curated-runs/allowlist.yaml`

**Changes**
```yaml
# Add two entries
- run_id: gf-01-cross-substrate-langchain
  substrate_claim_level: reproduced
  substrate_execution: reproduced
  repro_ref: tests/cross-substrate/gf-01/langchain/generate_pack.py
  equivalence_ref: Validation_Lab/releases/v0.2/artifacts/equivalence/gf-01.json
  
- run_id: gf-01-cross-substrate-a2a
  substrate_claim_level: reproduced
  substrate_execution: reproduced
  repro_ref: tests/cross-substrate/gf-01/a2a/generate_pack.sh
  equivalence_ref: Validation_Lab/releases/v0.2/artifacts/equivalence/gf-01.json
```

**DoD**
```bash
# Verify repro_ref paths exist
ls tests/cross-substrate/gf-01/langchain/generate_pack.py
ls tests/cross-substrate/gf-01/a2a/generate_pack.sh

# Verify equivalence_ref exists
ls Validation_Lab/releases/v0.2/artifacts/equivalence/gf-01.json
```

---

## Phase IV — W7 MCP Tool-call

### W7-1: Echo Server

**Files**
- `examples/mcp-servers/echo/index.ts`
- `examples/mcp-servers/echo/package.json`
- `examples/mcp-servers/echo/README.md` ✅ (done)

**Implementation**
```typescript
// Minimal echo server (stdio MCP)
process.stdin.on('data', (chunk) => {
  const req = JSON.parse(chunk);
  const resp = { ...req, echo: true };
  process.stdout.write(JSON.stringify(resp) + '\n');
});
```

**DoD**
```bash
cd examples/mcp-servers/echo
npm install
npm start &

# Test
echo '{"tool":"echo","input":"test"}' | npm start
```

---

### W7-2: Tool-call Flow

**Files**
- `tests/golden/flows/tool-call-flow/input/*`
- `tests/golden/flows/tool-call-flow/invariants.yaml` ✅ (done)
- `tests/golden/flows/tool-call-flow/README.md` ✅ (done)

**DoD**
```bash
# Run harness/evaluator
# Verify 3 invariants pass (S1 only)
```

---

## Phase V — PJT Gates

### PJT-01: Claim Traceability

**Files**
- `scripts/gates/claim-traceability-gate.mjs`

**Implementation**
```javascript
const KEY_PATHS = [
  'MPLP_website/app/page.tsx',
  'MPLP_website/app/about/page.tsx',
  'docs/docs/overview/index.mdx',
  'Validation_Lab/app/about/page.tsx'
];

// Check: claim patterns without claim_id nearby
```

**DoD**
```bash
node scripts/gates/claim-traceability-gate.mjs
# Exit 0 (no unmapped claims)
```

---

### PJT-02: Strength Honesty

**Files**
- `scripts/gates/strength-honesty-gate.mjs`

**Implementation**
```javascript
// For runs with substrate_claim_level=reproduced:
// 1. repro_ref exists
// 2. File is executable (bash -n or python -m py_compile)
```

**DoD**
```bash
node scripts/gates/strength-honesty-gate.mjs
# Validates 2 new reproduced runs
```

---

### CI Integration

**File**
- `.github/workflows/gates.yml`

**Changes**
```yaml
# Add after existing gates
- name: PJT Gates
  run: |
    node scripts/gates/claim-traceability-gate.mjs
    node scripts/gates/strength-honesty-gate.mjs
```

---

## Phase VI — Seal & Manifest

### Seal Document

**File**
- `Validation_Lab/releases/v0.2/phase-6.4-v0.2-interoperability-seal.md`

**Contents**
```markdown
# Phase 6.4 Seal — v0.2 Interoperability

## W6 Reproduced Runs
- gf-01-cross-substrate-langchain
- gf-01-cross-substrate-a2a

## Verification Commands
cd tests/cross-substrate/gf-01/langchain && python generate_pack.py
cd tests/cross-substrate/gf-01/a2a && bash generate_pack.sh
npx tsx tests/cross-substrate/gf-01/verify_equivalence.ts

## Gates
node scripts/gates/claim-traceability-gate.mjs
node scripts/gates/strength-honesty-gate.mjs
```

---

### Manifest Entry

**File**
- `Validation_Lab/releases/v0.1/master-evidence-manifest.v0.1.json`

**Changes**
```json
"phase_6_4": {
  "document": "phase-6.4-v0.2-interoperability-seal.md",
  "description": "v0.2: Cross-substrate S4 + MCP tool-call S1 + PJT gates"
}
```

---

## Common Failure Modes

| # | Failure | Prevention |
|---|---------|------------|
| 1 | Trace missing/malformed | Verify evidence_minimums includes trace_present |
| 2 | Hash instability | Test: run twice, diff output |
| 3 | repro_ref drift | Keep allowlist/scripts in sync |
| 4 | W7 accidentally S2 | No Plan↔Trace links in invariants |
| 5 | "Endorsed" language | README audit before merge |
